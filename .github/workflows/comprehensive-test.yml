name: Comprehensive Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM for nightly testing

jobs:
  unit-tests:
    name: Unit Tests - Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12', '3.13']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
      with:
        enable-cache: true
    
    - name: Install dependencies
      run: |
        uv venv
        source .venv/bin/activate
        uv pip install -e ".[dev]"
    
    - name: Run unit tests with coverage
      run: |
        uv run pytest tests/ -v --cov=cmdrdata --cov-report=xml --cov-report=term-missing
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
    
    - name: Type checking with mypy
      run: |
        uv run mypy cmdrdata --strict
      continue-on-error: true
    
    - name: Lint with black and isort
      run: |
        uv run black --check cmdrdata tests
        uv run isort --check-only cmdrdata tests

  property-based-tests:
    name: Property-Based Testing (Hypothesis)
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
    
    - name: Install dependencies
      run: |
        uv venv
        source .venv/bin/activate
        uv pip install -e ".[dev]"
        uv pip install hypothesis hypothesis-jsonschema
    
    - name: Run property-based tests
      run: |
        # Run hypothesis tests from the test suite
        uv run pytest tests/test_comprehensive.py::TestHypothesis -v --tb=short

  mutation-tests:
    name: Mutation Testing
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
    
    - name: Install dependencies
      run: |
        uv venv
        source .venv/bin/activate
        uv pip install -e ".[dev]"
        uv pip install mutmut
    
    - name: Run mutation tests on critical modules
      run: |
        # Test critical billing and tracking code
        uv run mutmut run --paths-to-mutate cmdrdata/tracker.py --runner "pytest tests/"
      continue-on-error: true
    
    - name: Show mutation test results
      run: |
        uv run mutmut results
      if: always()

  integration-tests:
    name: Integration Tests (All Providers)
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install uv
      uses: astral-sh/setup-uv@v3
    
    - name: Install dependencies
      run: |
        uv venv
        source .venv/bin/activate
        uv pip install -e ".[dev]"
        uv pip install openai anthropic google-generativeai cohere
    
    - name: Run provider integration tests
      env:
        CMDRDATA_API_KEY: ${{ secrets.CMDRDATA_API_KEY }}
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        COHERE_API_KEY: ${{ secrets.COHERE_API_KEY }}
      run: |
        uv run python test_real_providers.py
      continue-on-error: true

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Run Bandit security scan
      run: |
        pip install bandit
        bandit -r cmdrdata/ -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Check for hardcoded secrets
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD

  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install pytest-benchmark cmdrdata
    
    - name: Run performance benchmarks
      run: |
        cat << 'EOF' > test_performance.py
        import pytest
        from cmdrdata import CmdrData
        
        def test_wrapper_overhead(benchmark):
            """Benchmark the overhead of wrapping a client"""
            def create_wrapper():
                return CmdrData(
                    client=None,
                    cmdrdata_api_key="test-key",
                    customer_id="test-customer"
                )
            
            result = benchmark(create_wrapper)
            assert result is not None
        
        def test_metadata_processing(benchmark):
            """Benchmark metadata processing"""
            metadata = {"key": "value", "nested": {"data": "test"}} * 100
            
            def process_metadata():
                client = CmdrData(
                    client=None,
                    cmdrdata_api_key="test-key",
                    metadata=metadata
                )
                return client.metadata
            
            result = benchmark(process_metadata)
            assert result is not None
        EOF
        
        pytest test_performance.py -v --benchmark-only
      continue-on-error: true

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, property-based-tests, mutation-tests, integration-tests, playwright-e2e, security-scan, performance-benchmarks]
    if: always()
    
    steps:
    - name: Test Results Summary
      run: |
        echo "## Test Suite Summary"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Property-Based Tests: ${{ needs.property-based-tests.result }}"
        echo "Mutation Tests: ${{ needs.mutation-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "E2E Tests: ${{ needs.playwright-e2e.result }}"
        echo "Security Scan: ${{ needs.security-scan.result }}"
        echo "Performance: ${{ needs.performance-benchmarks.result }}"